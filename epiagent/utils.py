import numpy as np
import pandas as pd
import scanpy as sc
import ot
import torch
from sklearn.mixture import GaussianMixture
import faiss

def generate_adata_for_OSP(adata, 
                           cell_embedding_key="cell_embeddings_zero_shot",
                           perturbation_label="condition",
                           pre_label="resting",
                           post_label="stimulated",
                           cell_type_label="cell_type"):
    """
    Generates a new AnnData object tailored for the task of cellular response prediction under 
    Out-of-Sample Stimulated Perturbation (OSP). This function processes the input adata by 
    performing Optimal Transport (OT) matching between pre-perturbation (e.g., "resting") and 
    post-perturbation (e.g., "stimulated") cells, and then constructs a new AnnData object 
    containing three groups:
        1. Post-perturbation cells (with original cell_sentences as predicted indices),
        2. Pre-perturbation cells (with original cell_sentences as predicted indices),
        3. A mapping of pre-perturbation cells to post-perturbation cells via OT matching 
           (with predicted indices replaced by the matched post cellâ€™s cell_sentences and 
           condition updated to "Resting_mapping_to_stimulated").
    
    Detailed Steps:
    1. Validate that the required fields exist in the input AnnData:
         - 'cell_sentences' in adata.obs (generated by prior preprocessing with global_TFIDF and tokenization).
         - The specified cell embedding key in adata.obsm.
         - The perturbation label column in adata.obs.
         - If provided, the cell type label column in adata.obs.
    2. Extract cell embeddings from adata.obsm using the provided cell_embedding_key.
    3. Split the observation DataFrame (adata.obs) into pre-perturbation and post-perturbation groups 
       based on the perturbation_label.
    4. Perform OT matching between post-perturbation (stimulated) and pre-perturbation (resting) cells.
         - If cell_type_label is provided (not None), perform OT matching separately for each cell type.
         - Otherwise, perform OT matching on the entire pre and post groups.
         - The OT matching uses cosine distance between the cell embeddings and finds, for each 
           pre-perturbation cell, the corresponding post-perturbation cell with maximum transport mass.
    5. Generate new observation columns:
         - Create a new column "predicted_cell_indices" in which, for post-perturbation cells, the value 
           is the same as the original "cell_sentences".
         - For pre-perturbation cells, the same is initially set.
         - A new mapping DataFrame for pre-perturbation cells is generated where "predicted_cell_indices" 
           is replaced with the cell_sentences of the matched post-perturbation cell (from OT), and the 
           perturbation label is updated to "Resting_mapping_to_stimulated".
    6. Construct a new AnnData object by concatenating:
         - The post-perturbation group,
         - The pre-perturbation group,
         - The mapped pre-perturbation group (using matched post cells).
    7. Reset the observation index and update adata.obs with the newly generated metadata.
    
    Parameters:
        adata (AnnData): The input AnnData object containing single-cell data. It must include:
            - adata.obs['cell_sentences']: A column with tokenized cell sentence data.
        cell_embedding_key (str): The key in adata.obsm where the zero-shot cell embeddings are stored 
            (default: "cell_embeddings_zero_shot").
        perturbation_label (str): The key in adata.obs corresponding to perturbation-related labels 
            (default: "condition").
        pre_label (str): The label in adata.obs[perturbation_label] for pre-perturbation cells 
            (default: "resting").
        post_label (str): The label in adata.obs[perturbation_label] for post-perturbation cells 
            (default: "stimulated").
        cell_type_label (str or None): The key in adata.obs corresponding to cell type labels 
            (default: "cell_type"). If set to None, OT matching is performed on the entire dataset 
            without stratification by cell type.
    
    Returns:
        AnnData: A new AnnData object prepared for the OSP task, with updated observation metadata 
                 and predicted cell indices based on OT matching.
    
    Raises:
        ValueError: If any of the required fields (e.g., 'cell_sentences' in obs, specified embedding 
                    or label keys) are missing.
    """
    # --- Step 1: Validate required fields ---
    # Check that 'cell_sentences' exists in adata.obs
    if 'cell_sentences' not in adata.obs.columns:
        raise ValueError("The input adata does not contain 'cell_sentences'. "
                         "Please perform data preprocessing using global_TFIDF and tokenization first.")
    
    # Check that the specified cell_embedding_key exists in adata.obsm
    if cell_embedding_key not in adata.obsm.keys():
        raise ValueError(f"The specified cell embedding key '{cell_embedding_key}' was not found in adata.obsm.")
    
    # Check that perturbation_label exists in adata.obs
    if perturbation_label not in adata.obs.columns:
        raise ValueError(f"The specified perturbation label '{perturbation_label}' was not found in adata.obs.")
    
    # Check that pre_label and post_label exist in the perturbation_label column
    if not any(adata.obs[perturbation_label] == pre_label):
        raise ValueError(f"No cells with the pre-perturbation label '{pre_label}' found in adata.obs['{perturbation_label}'].")
    if not any(adata.obs[perturbation_label] == post_label):
        raise ValueError(f"No cells with the post-perturbation label '{post_label}' found in adata.obs['{perturbation_label}'].")
    
    # If cell_type_label is provided (i.e., not None), check that it exists in adata.obs
    if cell_type_label is not None and cell_type_label not in adata.obs.columns:
        raise ValueError(f"The specified cell type label '{cell_type_label}' was not found in adata.obs.")
    
    # --- Step 2: Extract necessary data ---
    # Make a copy of adata.obs as a DataFrame for processing
    obs_df = adata.obs.copy()
    
    # Extract cell embeddings (assumed to be a numpy array)
    cell_embeddings = adata.obsm[cell_embedding_key]
    if isinstance(cell_embeddings, torch.Tensor):
        cell_embeddings = cell_embeddings.cpu().detach().numpy()
    
    # Create a new column "cell_indices" if not already present.
    # We assume that "cell_sentences" uniquely represent each cell.
    if 'cell_indices' not in obs_df.columns:
        obs_df['cell_indices'] = obs_df['cell_sentences']
    
    # Initialize a new column "predicted_cell_indices" as a copy of cell_indices
    obs_df['predicted_cell_indices'] = obs_df['cell_indices']
    
    # --- Step 3: Split data into pre- and post-perturbation groups ---
    # Identify indices for pre-perturbation (e.g., resting) and post-perturbation (e.g., stimulated) cells.
    pre_mask = obs_df[perturbation_label] == pre_label
    post_mask = obs_df[perturbation_label] == post_label
    
    # Create separate DataFrames for post-perturbation and pre-perturbation cells
    df_post = obs_df[post_mask].copy().reset_index(drop=True)
    df_pre = obs_df[pre_mask].copy().reset_index(drop=True)
    
    # Retrieve the corresponding embeddings for each group using boolean masks.
    # We assume that the order in obs_df matches the order in cell_embeddings.
    emb_post = cell_embeddings[post_mask.values]
    emb_pre = cell_embeddings[pre_mask.values]
    
    # --- Step 4: Perform Optimal Transport (OT) Matching ---
    # The goal is to match each pre-perturbation cell with a post-perturbation cell based on their embeddings.
    # If cell_type_label is provided, OT matching is performed within each cell type; otherwise, it is done on the entire groups.
    
    # Initialize an array to store the OT matching result for pre-perturbation cells.
    total_match_idx = np.full(df_pre.shape[0], -1, dtype=int)
    
    if cell_type_label is not None:
        # Get the unique cell types present in the pre-perturbation group.
        cell_types = df_pre[cell_type_label].unique()
        for ctype in cell_types:
            # Filter pre- and post- DataFrames for the current cell type.
            idx_pre_type = df_pre[df_pre[cell_type_label] == ctype].index
            idx_post_type = df_post[df_post[cell_type_label] == ctype].index
            
            # Skip if no cells of the current type exist in either group.
            if len(idx_pre_type) == 0 or len(idx_post_type) == 0:
                continue
            
            # Extract embeddings for the current cell type.
            emb_pre_type = emb_pre[idx_pre_type]
            emb_post_type = emb_post[idx_post_type]
            
            # Compute the cost (distance) matrix using cosine distance.
            M = ot.dist(emb_post_type, emb_pre_type, metric='cosine')
            
            # Define uniform weight distributions for both groups.
            weights_post = torch.ones(emb_post_type.shape[0]) / emb_post_type.shape[0]
            weights_pre = torch.ones(emb_pre_type.shape[0]) / emb_pre_type.shape[0]
            
            # Convert the cost matrix to a torch tensor.
            M_tensor = torch.tensor(M, dtype=torch.float)
            
            # Compute the optimal transport plan using Earth Mover's Distance (EMD).
            G = ot.emd(weights_post, weights_pre, M_tensor, numItermax=2000000)
            
            # For each pre-perturbation cell (column in G), determine the index of the post cell with the maximum transport value.
            match_idx_local = torch.max(G, dim=0)[1].numpy()  # This gives indices relative to emb_post_type
            
            # Convert local post indices to global indices in df_post.
            global_post_indices = np.array(df_post.index[idx_post_type])[match_idx_local]
            
            # Assign the matched global post indices to the corresponding positions in total_match_idx.
            total_match_idx[idx_pre_type] = global_post_indices
    else:
        # If no cell type stratification is required, perform OT matching on the entire groups.
        M = ot.dist(emb_post, emb_pre, metric='cosine')
        weights_post = torch.ones(emb_post.shape[0]) / emb_post.shape[0]
        weights_pre = torch.ones(emb_pre.shape[0]) / emb_pre.shape[0]
        M_tensor = torch.tensor(M, dtype=torch.float)
        G = ot.emd(weights_post, weights_pre, M_tensor, numItermax=2000000)
        match_idx_global = torch.max(G, dim=0)[1].numpy()
        total_match_idx = match_idx_global  # Matches for all pre-perturbation cells
    
    # Ensure that all pre-perturbation cells have been matched.
    if (total_match_idx == -1).any():
        raise ValueError("Some pre-perturbation cells were not matched to any post-perturbation cells via OT.")
    
    # --- Step 5: Generate the Mapped Pre-perturbation Data ---
    # For the mapped pre-perturbation cells, update the predicted_cell_indices to be the cell_sentences 
    # of the matched post-perturbation cells. Also, update the perturbation label to indicate mapping.
    df_pre_mapping = df_pre.copy()
    # The matched post cell's "cell_indices" (or cell_sentences) from df_post are used.
    matched_post_cell_sentences = df_post.loc[total_match_idx, 'cell_indices'].values
    df_pre_mapping['predicted_cell_indices'] = matched_post_cell_sentences
    df_pre_mapping[perturbation_label] = pre_label+"_mapping_to_"+post_label
    
    # --- Step 6: Construct the New AnnData Object ---
    # Combine the three groups: post-perturbation, pre-perturbation, and the mapped pre-perturbation cells.
    # The order is: [post, pre, mapped_pre]
    new_obs_df = pd.concat([df_post, df_pre, df_pre_mapping], ignore_index=True)
    
    # Create new AnnData objects corresponding to each group using the original adata.
    adata_post = adata[adata.obs[perturbation_label] == post_label].copy()
    adata_pre = adata[adata.obs[perturbation_label] == pre_label].copy()
    # For the mapped group, use the post-perturbation cells corresponding to the OT matching.
    adata_pre_mapped = adata_post[total_match_idx].copy()
    
    # Concatenate the three AnnData objects. The join is set to 'outer' to include all features.
    new_adata = sc.concat([adata_post, adata_pre, adata_pre_mapped], join='outer')
    
    # Reset the observation index to sequential strings.
    new_adata.obs.index = [str(i) for i in range(new_adata.shape[0])]
    
    # Replace new_adata.obs with the combined new observation DataFrame.
    new_adata.obs = new_obs_df.copy()

    # Assign 'label_for_classification' for discriminator.
    new_adata.obs['label_for_classification'] = 0
    new_adata.obs.loc[new_adata.obs['condition'] == pre_label, 'label_for_classification'] = 1
    
    # Return the newly generated AnnData object tailored for OSP.
    return new_adata



def generate_adata_for_RDI(adata, 
                            cell_embedding_key="cell_embeddings_zero_shot",
                            batch_label="dataset"):
    """
    Generates a new AnnData object tailored for the task of reference data integration (RDI). This function processes
    the input adata by performing Optimal Transport (OT) matching between cells from different batches and then constructs 
    a new AnnData object containing integrated cells.

    Detailed Steps:
    1. Add two new columns to the AnnData object: "source" (set to "raw data") and "predicted_cell_sentences"
       (copy of "cell_sentences").
    2. Split the input data based on batch information specified in the "batch_label" column of adata.obs.
    3. Perform OT matching between different batches using cell embeddings.
    4. After performing OT, compute the matching distances, and use Gaussian Mixture Models (GMM) to filter out poor matches.
    5. For the selected cell matches, update the "cell_sentences" and "dataset" columns to simulate the data integration.
    6. Concatenate the matched cells and return a new AnnData object containing the integrated data.

    Parameters:
        adata (AnnData): The input AnnData object containing single-cell data. It must include:
            - adata.obs['cell_sentences']: A column with tokenized cell sentence data.
        cell_embedding_key (str): The key in adata.obsm where the zero-shot cell embeddings are stored 
            (default: "cell_embeddings_zero_shot").
        batch_label (str): The key in adata.obs corresponding to batch labels (default: "dataset").
    
    Returns:
        AnnData: A new AnnData object prepared for reference data integration, with updated observation metadata
                 and simulated cell data based on OT matching.
    
    Raises:
        ValueError: If any of the required fields (e.g., 'cell_sentences' in obs, specified embedding or label keys) 
                    are missing.
    """
    # --- Step 1: Validate required fields ---
    # Check that 'cell_sentences' exists in adata.obs
    if 'cell_sentences' not in adata.obs.columns:
        raise ValueError("The input adata does not contain 'cell_sentences'. "
                         "Please perform data preprocessing using global_TFIDF and tokenization first.")
    
    # Check that the specified cell_embedding_key exists in adata.obsm
    if cell_embedding_key not in adata.obsm.keys():
        raise ValueError(f"The specified cell embedding key '{cell_embedding_key}' was not found in adata.obsm.")
    
    # Check that batch_label exists in adata.obs
    if batch_label not in adata.obs.columns:
        raise ValueError(f"The specified batch label '{batch_label}' was not found in adata.obs.")
    
    # --- Step 2: Add new columns for source and predicted_cell_sentences ---
    # Add a new column 'source' to adata.obs
    adata.obs['source'] = 'raw data'

    # Create a new column 'predicted_cell_sentences' by copying 'cell_sentences'
    adata.obs['predicted_cell_sentences'] = adata.obs['cell_sentences']

    # --- Step 3: Split data into different batches ---
    # Get unique batches from the batch_label column
    unique_batches = adata.obs[batch_label].unique()

    # Split the data into separate batches
    batch_adata_list = [adata[adata.obs[batch_label] == batch].copy() for batch in unique_batches]

    # --- Step 4: Perform Optimal Transport (OT) Matching ---
    total_combined_adata = []
    
    # Perform OT matching between each pair of batches
    for i, adata_A in enumerate(batch_adata_list):
        for j, adata_B in enumerate(batch_adata_list):
            if adata_A.n_obs < adata_B.n_obs or (adata_A.n_obs == adata_B.n_obs and i < j):  # Avoid redundant matching, only do once for each pair
                # Extract the cell embeddings for the two batches
                embeddings_A = adata_A.obsm[cell_embedding_key]
                embeddings_B = adata_B.obsm[cell_embedding_key]
                
                # Compute the cost (distance) matrix using cosine distance
                M = ot.dist(embeddings_A, embeddings_B, metric='cosine')
                
                # Define uniform weight distributions for both groups
                weights_A = torch.ones(embeddings_A.shape[0]) / embeddings_A.shape[0]
                weights_B = torch.ones(embeddings_B.shape[0]) / embeddings_B.shape[0]
                
                # Compute the optimal transport plan using Earth Mover's Distance (EMD)
                M_tensor = torch.tensor(M, dtype=torch.float32)
                G = ot.emd(weights_A, weights_B, M_tensor, numItermax=2000000)
                
                # Find the best matches (columns in G corresponding to embeddings_B)
                match_idx = torch.max(G, dim=0)[1].numpy()

                # Calculate the matching distances for further filtering
                matched_distances = np.array([M[i, match_idx[i]] for i in range(len(match_idx))])
                
                # Use Gaussian Mixture Model (GMM) to select better matches based on distance
                gmm = GaussianMixture(n_components=2, random_state=0)
                gmm.fit(matched_distances.reshape(-1, 1))
                labels = gmm.predict(matched_distances.reshape(-1, 1))

                # Select the group with the smaller mean distance
                smaller_mean_index = np.argmin(gmm.means_.flatten())
                selected_indices = np.where(labels == smaller_mean_index)[0]

                # Extract the selected matching cells from both batches
                selected_adata_A = adata_A[selected_indices].copy()
                selected_adata_B = adata_B[match_idx[selected_indices]].copy()

                # Update the 'cell_sentences' and 'dataset' columns after matching
                temp_sentences_A = selected_adata_A.obs['cell_sentences'].copy()
                selected_adata_A.obs['cell_sentences'] = selected_adata_B.obs['cell_sentences'].tolist()
                selected_adata_B.obs['cell_sentences'] = temp_sentences_A.tolist()

                # Swap 'dataset' labels between the two batches
                temp_dataset_A = selected_adata_A.obs['dataset'].copy()
                selected_adata_A.obs['dataset'] = selected_adata_B.obs['dataset'].tolist()
                selected_adata_B.obs['dataset'] = temp_dataset_A.tolist()

                # Combine the selected cells from both batches
                combined_adata = selected_adata_A.concatenate(selected_adata_B)

                # Mark the combined data as 'simulated' data
                combined_adata.obs['source'] = 'simulated data'

                # Append the combined data to the final list
                total_combined_adata.append(combined_adata)

    # --- Step 5: Concatenate All Combined Data ---
    # Concatenate all combined batches into one AnnData object
    final_adata = adata
    for combined_adata in total_combined_adata:
        final_adata = final_adata.concatenate(combined_adata)

    # --- Step 6: Return the Integrated AnnData ---
    # Update the observation index to ensure it is sequential
    final_adata.obs.index = [str(i) for i in range(final_adata.shape[0])]

    return final_adata


def label_transfer_for_QDM(integrated_adata, 
                           embedding_key='cell_embeddings_fine_tuned_BC', 
                           k=20, 
                           source_key='type', 
                           source_values=['reference data', 'query data'],
                           cell_type_key='cell_type'):
    """
    Transfers labels from reference data to query data using FAISS-based nearest neighbor search,
    for the task of query data mapping (QDM) in reference data integration.
    
    The function splits the integrated AnnData object into reference and query subsets based on the 
    specified `source_key` (e.g., 'type') and its values (e.g., ['reference data', 'query data']).
    It then extracts embeddings from the specified `embedding_key` and computes two sets of nearest neighbors:
    one based on Euclidean (L2) distances and another based on cosine similarity. For each query cell, the label 
    of the most common cell type (from `cell_type_key` in `obs`) among its K nearest neighbors is assigned as 
    the predicted label.
    
    Args:
        integrated_adata (AnnData): The integrated AnnData object containing both reference and query cells.
        embedding_key (str): The key in `obsm` where the cell embeddings are stored (default: 'cell_embeddings_fine_tuned_BC').
        k (int): The number of nearest neighbors to use for label transfer (default: 20).
        source_key (str): The key in `obs` that indicates the data source (e.g., 'type') (default: 'type').
        source_values (list of str): A list of two strings indicating the labels for reference and query data 
            respectively (default: ['reference data', 'query data']).
        cell_type_key (str): The key in `obs` where the true cell type labels are stored (default: 'cell_type').
    
    Returns:
        query_data (AnnData): The query subset of the integrated data with two new columns in `obs`:
            - 'predicted_label_L2_k{k}': Predicted cell type label based on Euclidean (L2) nearest neighbors.
            - 'predicted_label_cosine_k{k}': Predicted cell type label based on cosine similarity nearest neighbors.
    """
    # Split integrated_adata into reference and query based on the source_key and provided source_values.
    reference_data = integrated_adata[integrated_adata.obs[source_key] == source_values[0]].copy()
    query_data = integrated_adata[integrated_adata.obs[source_key] == source_values[1]].copy()
    
    # Extract embeddings from obsm using the provided embedding_key.
    query_embedding = query_data.obsm[embedding_key].astype(np.float32)
    reference_embedding = reference_data.obsm[embedding_key].astype(np.float32)
    
    # ---------------------------
    # Euclidean (L2) Nearest Neighbor Label Transfer
    # ---------------------------
    index_l2 = faiss.IndexFlatL2(reference_embedding.shape[1])
    index_l2.add(reference_embedding)
    
    # Perform KNN search using L2 distance.
    distances_l2, indices_l2 = index_l2.search(query_embedding, k)
    
    predicted_labels_l2 = []
    # For each query cell, determine the predicted cell type by majority vote among its k-nearest neighbors.
    for neighbors in indices_l2:
        neighbor_labels = reference_data.obs[cell_type_key].values[neighbors]
        predicted_label = pd.Series(neighbor_labels).mode()[0]
        predicted_labels_l2.append(predicted_label)
    
    # Add the L2-based predicted labels to query_data.obs.
    query_data.obs[f'predicted_label_L2_k{k}'] = predicted_labels_l2
    
    # ---------------------------
    # Cosine Similarity Nearest Neighbor Label Transfer
    # ---------------------------
    # Normalize embeddings to unit length for cosine similarity computation.
    faiss.normalize_L2(reference_embedding)
    faiss.normalize_L2(query_embedding)
    
    index_cosine = faiss.IndexFlatIP(reference_embedding.shape[1])
    index_cosine.add(reference_embedding)
    
    distances_cosine, indices_cosine = index_cosine.search(query_embedding, k)
    
    predicted_labels_cosine = []
    # For each query cell, determine the predicted cell type by majority vote among its k-nearest neighbors.
    for neighbors in indices_cosine:
        neighbor_labels = reference_data.obs[cell_type_key].values[neighbors]
        predicted_label = pd.Series(neighbor_labels).mode()[0]
        predicted_labels_cosine.append(predicted_label)
    
    # Add the cosine-based predicted labels to query_data.obs.
    query_data.obs[f'predicted_label_cosine_k{k}'] = predicted_labels_cosine

    # Return the query_data AnnData object with transferred labels.
    return query_data